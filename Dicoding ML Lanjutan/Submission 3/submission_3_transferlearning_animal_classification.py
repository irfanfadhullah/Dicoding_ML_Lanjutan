# -*- coding: utf-8 -*-
"""Submission 3_TransferLearning Animal Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qon7r01mYVcq7_RUcenGwFATZDBghu7j
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
import math

import io, zipfile,os
!pip install kaggle

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d alessiocorrado99/animals10

"""Alasan memilih dataset ini adalah agar memenuhi kriteria Bintang 5 Dicoding, yaitu resolusi yang beragam, lebih dari 3 class"""

zip_ref = zipfile.ZipFile("/content/animals10.zip", 'r') #file yang ingin di ekstrak
zip_ref.extractall("/content") #ekstrack dataset ke folder temp di google collab
zip_ref.close()

train_path='/content/raw-img/'

from tensorflow.keras.preprocessing.image import ImageDataGenerator
train_datagen = ImageDataGenerator( rescale=1./255,
                                   shear_range=0.2,
                                   samplewise_center = True,
                                   zoom_range=0.2,
                                   width_shift_range=0.1,
                                   height_shift_range=0.1,
                                   rotation_range=45,
                                   horizontal_flip=True,
                                   vertical_flip=True,
                                   validation_split = .2
)
traindata= train_path
validationdata = train_path
batch_size = 128

#img_height=150
#img_width= 150

train_gen = train_datagen.flow_from_directory( 
    directory=train_path,
    batch_size=batch_size,
    shuffle=True,
    target_size=(150,150),
    class_mode='categorical',
    subset='training'
    )
validation_gen = train_datagen.flow_from_directory(
    directory=train_path,
    batch_size=batch_size,
    shuffle=True,
    target_size=(150,150),
    class_mode='categorical',
    subset='validation'
    )

from tensorflow.keras.applications import ResNet152V2
from tensorflow.keras.applications import EfficientNetB7
from tensorflow.keras.applications import VGG19

"""Alasan memakai PreTrained Model adalah saat menggunakan model buatan sendiri tidak mencapai accuracy yang maksimal, sekitar 70%"""

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('val_accuracy')>0.92)&(logs.get('accuracy')>0.92):
      print("\nAkurasi telah mencapai >92%!")
      self.model.stop_training = True
callbacks = myCallback()

checkpoint_path = "/content/cp.ckpt"
checkpoint_dir = os.path.dirname(checkpoint_path)

# Buat Callback untuk save weight model, jaga2 kalau connectionloss
cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,
                                                 save_weights_only=True,
                                                 verbose=2)

#Membuat fungsi menurunkan Learning Rate saat berada di Plateau
reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_loss', 
                                                 factor = 0.2, 
                                                 patience = 2, 
                                                 verbose = 1, 
                                                 min_delta=0.001, 
                                                 min_lr = 1e-10)

model = tf.keras.Sequential([
                                     VGG19(weights="imagenet", include_top=False, input_shape=(150,150, 3)),
                                     #tf.keras.layers.Dropout(0.2),
                                     tf.keras.layers.Conv2D(128,(3,3),activation='relu',padding='same'),
                                     tf.keras.layers.MaxPooling2D(2,2),
                                     tf.keras.layers.Dropout(0.2),
                                     #tf.keras.layers.BatchNormalization(),
                                     tf.keras.layers.Flatten(),
                                     tf.keras.layers.Dense(256,activation='relu'),
                                     tf.keras.layers.Dropout(0.2),
                                     tf.keras.layers.Dense(128,activation='relu'),
                                     tf.keras.layers.Dropout(0.2),
                                     tf.keras.layers.Dense(10,activation='softmax')
])
model.layers[0].trainable = True
model.summary()

#steps = compute_steps_per_epoch(train_gen.n)
#val_steps = compute_steps_per_epoch(validation_gen.n)

model.compile(optimizer=tf.keras.optimizers.SGD(lr=1e-3, momentum=0.9),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

history = model.fit(train_gen,
                    steps_per_epoch=train_gen.n//train_gen.batch_size + 1,  # banyaknya step yang dieksekusi dalam setiap epoch yang dijalankan
                    callbacks=[callbacks,cp_callback,reduce_lr],
                    epochs=500,
                    validation_data=validation_gen, # menampilkan akurasi pengujian data validasi
                    validation_steps=validation_gen.n//validation_gen.batch_size + 1,  # banyaknya step yang dieksekusi dalam setiap epoch yang dijalankan
                    verbose=2)

"""Sebenarnya sudah dijalankan beberapa kali untuk model.fit <br>
Tidak langsung 88% pada epoch pertama, itu sudah running ke sekian kali

# Plotting Model
"""

import matplotlib.pyplot as plt
# Melihat Tingkat Akurasi Model
plt.plot(history.history['accuracy'])    # Plotting learning(model fit) history untuk akurasi
plt.plot(history.history['val_accuracy'])# Plotting learning(model fit) history untuk validation akurasi
plt.title('Tingkat Akurasi Model')        # Set Judul Gambar
plt.ylabel('Akurasi')                     # Set Label y-axis
plt.xlabel('Epoch')                       # Set Label x-axis
plt.legend(['Train', 'Test'], loc='upper left') #memberikan legend Gambar untuk memudahkan membaca
plt.show()

# # Melihat Tingkat Loss Model
plt.plot(history.history['loss'])     # Plotting learning(model fit) history untuk Loss
plt.plot(history.history['val_loss']) # Plotting learning(model fit) history untuk validation Loss
plt.title('Tingkat Loss Model')       # Set Judul Gambar
plt.ylabel('Loss')                        # Set Label y-axis
plt.xlabel('Epoch')                       # Set Label x-axis
plt.legend(['Train', 'Test'], loc='upper left') #memberikan legend Gambar untuk memudahkan membaca
plt.show()

"""Dari hasil evaluasi terlihat sedikit overfit, namun masih bisa di toleransi

# Save Model dan Convert Model
"""

MODEL_NAME = 'Animal_Classification'
model.save(MODEL_NAME)

model.save('Animal_Classification.h5')

# Convert model.
converter = tf.lite.TFLiteConverter.from_saved_model('/content/Animal_Classification')
tflite_model = converter.convert()

#Menyimpan Model.
with tf.io.gfile.GFile('/content/model.tflite', 'wb') as f:
  f.write(tflite_model)

from google.colab import drive
drive.mount('/content/drive')

