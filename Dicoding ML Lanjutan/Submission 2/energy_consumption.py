# -*- coding: utf-8 -*-
"""Energy Consumption.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eUsmS1ZBznsdY1jRyECoDMYz2iKfSnNh
"""

import pandas as pd
import numpy as np
from keras.layers import Dense, LSTM
import matplotlib.pyplot as plt
import tensorflow as tf

#!unzip 122_260_bundle_archive.zip

df = pd.read_csv('/content/energydata_complete.csv')
df.head()

df.info()

df.isnull().sum()

df['date']=pd.to_datetime(df['date'])
df.set_index('date', inplace=True)

df.head()

df['lights'].plot()
#datanya jelek di visualisasi

lights = df['lights'].resample('D') #resample per hari

plt.figure(figsize=(15,5))
lights.sum().plot()
plt.title('Penerangan per hari dalam jumlah',fontsize=20)
plt.tight_layout()
plt.show()

plt.figure(figsize=(15,5))
lights.mean().plot()
plt.title('Penerangan per hari dalam mean',fontsize=20)
plt.tight_layout()
plt.show()

#backup
df_new = df

data_resample = df_new.resample('h').mean() #diresample berdasarkan jam
nilai = data_resample.values

df = df.loc['2016-05-01':]
df = df.round(2)

test_days = 2
test_ind = test_days*144
test_ind

split_time = test_ind
data_train = nilai[:split_time,:]
data_test = nilai[split_time:]

from sklearn.preprocessing import MinMaxScaler
scaling = MinMaxScaler(feature_range=(0,1))
scaling.fit(data_train)

test_scaled = scaling.transform(data_train)
train_scaled = scaling.transform(data_test)

from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator

panjang = 144
batch_size = 1
generator = TimeseriesGenerator(train_scaled, train_scaled, length=panjang, batch_size=batch_size)
val_gen = TimeseriesGenerator(test_scaled, test_scaled, length = panjang, batch_size=batch_size)

X,y = generator[0]

model = tf.keras.Sequential([
                             tf.keras.layers.LSTM(100, input_shape=(panjang,train_scaled.shape[1]),return_sequences=True),
                             tf.keras.layers.Dropout(0.2),
                             tf.keras.layers.LSTM(50),
                             tf.keras.layers.Dropout(0.2),
                             tf.keras.layers.Dense(train_scaled.shape[1])
])
num_epochs = 100


from tensorflow.keras.callbacks import EarlyStopping
early_stop = EarlyStopping(monitor='val_loss',patience=4)

model.compile(loss = 'mean_squared_error',
              optimizer = 'adam',
              metrics = 'mae')

history = model.fit(generator, epochs = num_epochs, batch_size = 50,
                        validation_data = val_gen,callbacks = [early_stop],
                        verbose = 2)

import matplotlib.pyplot as plt
plt.plot(history.history['mae'])
plt.plot(history.history['val_mae'])
plt.title('MAE')
plt.ylabel('mae')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

